{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Краткое описание\n",
    "Разработка программы, которая обучает искусственную нейронную сеть (персептрон) распознавать два или более черно-белых изображения.\n",
    "\n",
    "## 1. Цель работы\n",
    "Изучить принципы работы и алгоритм обучения простейших искусственных нейронных сетей (НС).\n",
    "\n",
    "## 2. Порядок выполнения работы\n",
    "1. Изучить теоретическое введение.\n",
    "2. Сформировать обучающую выборку из 10+ изображений.\n",
    "3. Разработать компьютерную программу (среда разработки выбирается студентом самостоятельно).\n",
    "4. Провести серию из 5+ испытаний с различными исходными данными, выявить ограничения и недостатки однослойных НС для решения задач распознавания.\n",
    "5. Оформить отчет по лабораторной работе.\n",
    "\n",
    "## 3. Требования к исходным данным и функциональности компьютерной программы\n",
    "- В программе должна быть реализована возможность задания обучающей выборки из внешних файлов изображений.\n",
    "- Изображения должны быть черно-белыми (bitmap) и размером не менее 9 (3x3) пикселей.\n",
    "- Программа должна иметь два режима работы: обучения и распознавания.\n",
    "- Обучение должно производиться по стандартному алгоритму обучения персептрона с использованием дельта-правила.\n",
    "- В программе должны задаваться следующие настройки:\n",
    "  - количество входов нейрона, которое соответствует общему числу пикселей изображения\n",
    "  - коэффициент скорости обучения (если его значение постоянно)\n",
    "  - правильные варианты элементов обучающей выборки\n",
    "  - размер ошибки, при котором обучение персептрона завершается (опционально)\n",
    "\n",
    "### На экранной форме режима обучения должны отображаться:\n",
    "- элементы обучающей выборки (изображения)\n",
    "- настройки алгоритма обучения\n",
    "- текущие (итоговые) веса нейронов и значение порога активационной функции\n",
    "- протоколы результатов обучения (значения весов для каждой итерации)\n",
    "\n",
    "### На экранной форме режима распознавания должны отображаться:\n",
    "- распознаваемое изображение (должно выбираться из всего множества)\n",
    "- результат распознавания\n",
    "- веса нейронов и значение порога активационной функции\n",
    "- значения выходов всех нейронов до и после применения активационной функции\n",
    "\n",
    "## 4. Рекомендации по реализации\n",
    "- Для задания различной размерности распознаваемых изображений можно пользоваться одним типо-размером с максимальной разрешающей способностью, но при этом считывать только часть пикселей (например, от верхнего левого угла).\n",
    "- Для решения задач обучения двухмерное изображение N*M можно преобразовывать в одномерный вектор (массив) размерностью K=N*M.\n",
    "- При распознавании цветных изображений (RGB) каждому пикселю соответствует 3-х байтовая последовательность (24 входа).\n",
    "\n",
    "## 5. Содержание отчета\n",
    "- Название и цель работы\n",
    "- Задание, краткое описание предметной области и выбранной задачи\n",
    "- Блок-схема алгоритмов обучения и распознавания\n",
    "- Протоколы проведенных экспериментов (5+), представленные в форме таблиц и графиков (допускаются скриншоты в случае программной реализации этой функциональности)\n",
    "- Выводы и рекомендации по использованию НС для решения задач распознавания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение задания\n",
    "\n",
    "Выполнил: Журавлев Д. А. Группа 211-321 \n",
    "\n",
    "Учебный курс: Методы работы с большими данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "np.random.seed(6340)\n",
    "\n",
    "TRAINING_IMAGES_DIR = \"./materials/nn1/images/\"\n",
    "WEIGHTS_DIR = \"./materials/nn1/weights/\"\n",
    "IMAGE_SIZE = (50, 50)\n",
    "LEARNING_RATE = 0.1\n",
    "MIN_ERROR = 0.035\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data [('cross', 'cross_23', array([0, 0, 0, ..., 0, 0, 0])), ('polygon', 'polygon_15', array([0, 0, 0, ..., 0, 0, 0])), ('polygon', 'polygon_14', array([0, 0, 0, ..., 0, 0, 0])), ('cross', 'cross_22', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_1', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_3', array([0, 0, 0, ..., 0, 0, 0])), ('cross', 'cross_21', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_2', array([0, 0, 0, ..., 0, 0, 0])), ('cross', 'cross_25', array([0, 0, 0, ..., 0, 0, 0])), ('polygon', 'polygon_13', array([0, 0, 0, ..., 0, 0, 0])), ('polygon', 'polygon_12', array([0, 0, 0, ..., 0, 0, 0])), ('cross', 'cross_24', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_5', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_10', array([0, 0, 0, ..., 0, 0, 0])), ('polygon', 'polygon_11', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_4', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_8', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_17', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_16', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_9', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_20', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_7', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_18', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_19', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_6', array([0, 0, 0, ..., 0, 0, 0]))]\n",
      "Control data [('polygon', 'polygon_control', array([0, 0, 0, ..., 0, 0, 0])), ('star', 'star_control', array([0, 0, 0, ..., 0, 0, 0])), ('cross', 'cross_control', array([0, 0, 0, ..., 0, 0, 0])), ('rectangle', 'rectangle_control', array([0, 0, 0, ..., 0, 0, 0])), ('oval', 'oval_control', array([0, 0, 0, ..., 0, 0, 0]))]\n",
      "Group labels {'cross': 0, 'rectangle': 1, 'oval': 2, 'polygon': 3, 'star': 4}\n"
     ]
    }
   ],
   "source": [
    "def load_and_vectorize_images(directory, image_size):\n",
    "    train_vectors = []\n",
    "    control_vectors = []\n",
    "    for filename in os.listdir(directory):\n",
    "        image = Image.open(os.path.join(directory, filename)).convert(\"L\").resize(image_size)\n",
    "        vector = (np.array(image) < 128).astype(int).flatten()\n",
    "        group, name = str(filename).rsplit(\".\", 1)[0].split(\"_\")\n",
    "        data_entry = (group, f\"{group}_{name}\", vector)\n",
    "        if name == \"control\":\n",
    "            control_vectors.append(data_entry)\n",
    "        else: \n",
    "            train_vectors.append(data_entry)\n",
    "    return train_vectors, control_vectors\n",
    "\n",
    "train_data, control_data = load_and_vectorize_images(TRAINING_IMAGES_DIR, IMAGE_SIZE)\n",
    "\n",
    "group_labels = { y : x for x, y in enumerate( set( group[0] for group in train_data ) ) }\n",
    "\n",
    "print(f\"Train data {train_data}\\nControl data {control_data}\\nGroup labels {group_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train vectors\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Train labels\n",
      " [[1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 1]\n",
      " [0 0 1 0 0]]\n",
      " Control vectors\n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      " Contrpl labels\n",
      " [[0 0 0 1 0]\n",
      " [0 0 0 0 1]\n",
      " [1 0 0 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "def create_labeled_data(group_labels: dict, data: list):\n",
    "    vectors = []\n",
    "    labels = []\n",
    "    \n",
    "    for group, _, vector in data:\n",
    "        vectors.append(np.array(vector))\n",
    "        labels.append(group_labels[group])\n",
    "    \n",
    "    return np.array(vectors), np.eye(len(group_labels), dtype=int)[labels]\n",
    "\n",
    "train_vectors, train_labels = create_labeled_data(group_labels, train_data)\n",
    "control_vectors, control_labels = create_labeled_data(group_labels, control_data)\n",
    "\n",
    "print(f\"Train vectors\\n {train_vectors}\\nTrain labels\\n {train_labels}\\n Control vectors\\n {control_vectors}\\n Contrpl labels\\n {control_labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = np.random.randn(input_size, output_size)\n",
    "        self.bias = np.random.randn(output_size)\n",
    "\n",
    "    def activation(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def activation_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def train(self, X, y, epochs=10000):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.activation(np.dot(X, self.weights) + self.bias)\n",
    "            error = y - output\n",
    "            d_output = error * self.activation_derivative(output)\n",
    "            self.weights += np.dot(X.T, d_output) * self.learning_rate\n",
    "            self.bias += np.sum(d_output, axis=0) * self.learning_rate\n",
    "            loss = np.mean(np.abs(error))\n",
    "\n",
    "            if epoch % 10000 == 0: \n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "            if np.mean(np.abs(error)) <= MIN_ERROR:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}: Mininal error achived\")\n",
    "                break\n",
    "        \n",
    "        with open(WEIGHTS_DIR + 'weights.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(self.weights)\n",
    "\n",
    "        with open(WEIGHTS_DIR + 'bias.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerows(self.bias)\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.activation(np.dot(X, self.weights) + self.bias)\n",
    "        return np.argmax(output)\n",
    "    \n",
    "perceptron = Perceptron(\n",
    "    IMAGE_SIZE[0] * IMAGE_SIZE[1],\n",
    "    len(group_labels.keys()),\n",
    "    LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.43717475759866026\n",
      "Epoch 10000, Loss: 0.04962329212412908\n",
      "Epoch 20000, Loss: 0.041153374922060226\n",
      "Epoch 30000, Loss: 0.040946993998940105\n",
      "Epoch 40000, Loss: 0.040826391426408266\n",
      "Epoch 50000, Loss: 0.04074355731210883\n",
      "Epoch 60000, Loss: 0.04068250308888625\n",
      "Epoch 62628, Loss: 0.034604508618664084: Mininal error achived\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "iterable expected, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[243], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperceptron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[242], line 37\u001b[0m, in \u001b[0;36mPerceptron.train\u001b[0;34m(self, X, y, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(WEIGHTS_DIR \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbias.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m csvfile:\n\u001b[1;32m     36\u001b[0m     writer \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mwriter(csvfile)\n\u001b[0;32m---> 37\u001b[0m     \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mError\u001b[0m: iterable expected, not numpy.float64"
     ]
    }
   ],
   "source": [
    "\n",
    "perceptron.train(train_vectors, train_labels, epochs=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: polygon, expected: polygon\n",
      "✅ Prediction: polygon, expected: polygon\n",
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: rectangle, expected: rectangle\n",
      "❌ Prediction: oval, expected: rectangle\n",
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: rectangle, expected: rectangle\n",
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: polygon, expected: polygon\n",
      "✅ Prediction: polygon, expected: polygon\n",
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: rectangle, expected: rectangle\n",
      "✅ Prediction: oval, expected: oval\n",
      "✅ Prediction: polygon, expected: polygon\n",
      "✅ Prediction: rectangle, expected: rectangle\n",
      "✅ Prediction: oval, expected: oval\n",
      "❌ Prediction: polygon, expected: star\n",
      "✅ Prediction: star, expected: star\n",
      "✅ Prediction: oval, expected: oval\n",
      "❌ Prediction: oval, expected: star\n",
      "✅ Prediction: oval, expected: oval\n",
      "✅ Prediction: star, expected: star\n",
      "✅ Prediction: star, expected: star\n",
      "✅ Prediction: oval, expected: oval\n",
      "Точность на обучающих данных: 88.00%\n",
      "\n",
      "❌ Prediction: cross, expected: polygon\n",
      "✅ Prediction: star, expected: star\n",
      "✅ Prediction: cross, expected: cross\n",
      "✅ Prediction: rectangle, expected: rectangle\n",
      "✅ Prediction: oval, expected: oval\n",
      "Точность на контрольных данных: 80.00%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calc_accuracy(vectors, labels):\n",
    "    correct_predictions = 0\n",
    "    for vector, label in zip(vectors, labels):\n",
    "        prediction = perceptron.predict(vector)\n",
    "        predicted_group = [ i for i in group_labels if group_labels[i]==prediction ][0]\n",
    "        expected_group = [ i for i in group_labels if group_labels[i]==np.where(label == 1)[0][0] ][0]\n",
    "        prediction_correction = \"✅\" if expected_group == predicted_group else \"❌\"\n",
    "        print(f\"{prediction_correction} Prediction: {predicted_group}, expected: {expected_group}\")\n",
    "        if expected_group == predicted_group:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    return correct_predictions / len(vectors) * 100\n",
    "\n",
    "print(f\"Точность на обучающих данных: {calc_accuracy(train_vectors, train_labels):.2f}%\\n\")\n",
    "print(f\"Точность на контрольных данных: {calc_accuracy(control_vectors, control_labels):.2f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
