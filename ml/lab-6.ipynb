{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 6\n",
    "\n",
    "## Рекуррентные нейронные сети\n",
    "\n",
    "1. Цель работы: Изучение и практическое применение рекуррентных нейронных сетей для анализа и моделирования временных рядов.\n",
    "\n",
    "2. Основные задачи работы\n",
    "\n",
    "    1. Изучение теоретических основ рекуррентных нейронных сетей.\n",
    "\n",
    "    2. Разработка и обучение рекуррентной нейронной сети для анализа временных рядов.\n",
    "\n",
    "    3. Применение обученной модели для прогнозирования временных рядов.\n",
    "\n",
    "    4. Оценка и анализ полученных результатов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выполнение работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1. Задача генерации текста посимвольно с использованием RNN\n",
    "\n",
    "В данной задаче входной последовательностью для RNN являются первые шесть символов текста, а целью является предсказание следующего (седьмого) символа. Затем предсказанный символ добавляется к входной последовательности, и процесс повторяется для генерации последующих символов.\n",
    "\n",
    " \n",
    "\n",
    "Процесс рекуррентной генерации текста состоит из следующих шагов:\n",
    "\n",
    "1. Подготовка обучающего набора: Обучающий набор представляет собой текстовые данные, которые могут быть скопированы или взяты из какого-либо источника. Весь текст разбивается на отдельные символы, и каждый символ становится элементом последовательности.\n",
    "\n",
    "2. Предобработка данных: Символы текста преобразуются в числовой формат, например, с помощью one-hot encoding, где каждый символ представлен вектором размерности, равной общему количеству уникальных символов в обучающем наборе.\n",
    "\n",
    "3. Создание RNN модели: Модель RNN создается, состоящая из рекуррентного слоя (RNN layer) и выходного слоя (output layer). Рекуррентный слой обрабатывает входную последовательность символов и передает информацию о предыдущем состоянии в следующий шаг. Выходной слой генерирует вероятности для следующего символа.\n",
    "\n",
    "4. Обучение модели: RNN модель обучается на обучающем наборе с использованием метода обратного распространения ошибки. Происходит подбор оптимальных весов и параметров модели для минимизации ошибки предсказания следующего символа.\n",
    "\n",
    "5. Генерация текста: После завершения обучения модели можно использовать для генерации нового текста. Процесс начинается с задания начальной последовательности из шести символов. Затем RNN модель принимает эту последовательность в качестве входа и предсказывает вероятности для следующего символа. Символ с наибольшей вероятностью выбирается и добавляется к текущей последовательности. После этого процесс повторяется для генерации следующего символа. Таким образом, можно генерировать текст, символ за символом, продолжая последовательность до достижения заданной длины или условия остановки.\n",
    "\n",
    "6. Оценка результатов: Сгенерированный текст можно оценить с помощью различных метрик, таких как перплексия, сходство с исходным текстом или субъективное оценивание качества текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Подготовка набора данных временного ряда для обучения и тестирования модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальные символы: ['\\n', ' ', '!', \"'\", ',', '-', '.', ':', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_file_to_string(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# Загрузка текстовых данных\n",
    "text = read_file_to_string(\"./biblefull.txt\").lower()\n",
    "# Создание уникального набора символов\n",
    "chars = sorted(list(set(text)))\n",
    "print(f\"Уникальные символы: {chars}\")\n",
    "\n",
    "# Создание словаря для преобразования символов в индексы\n",
    "char_to_index = {c: i for i, c in enumerate(chars)}\n",
    "index_to_char = {i: c for i, c in enumerate(chars)}\n",
    "\n",
    "# Параметры\n",
    "seq_length = 12\n",
    "step = 1\n",
    "\n",
    "# Подготовка обучающих последовательностей\n",
    "sequences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - seq_length, step):\n",
    "    sequences.append(text[i: i + seq_length])\n",
    "    next_chars.append(text[i + seq_length])\n",
    "\n",
    "# Преобразование символов в one-hot encoding\n",
    "X = np.zeros((len(sequences), seq_length, len(chars)), dtype=np.bool_)\n",
    "y = np.zeros((len(sequences), len(chars)), dtype=np.bool_)\n",
    "\n",
    "for i, seq in enumerate(sequences):\n",
    "    for j, char in enumerate(seq):\n",
    "        X[i, j, char_to_index[char]] = 1\n",
    "    y[i, char_to_index[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Разработка архитектуры рекуррентной нейронной сети с использованием фреймворка глубокого обучения, такого как TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Создание улучшенной модели RNN\n",
    "model = Sequential([\n",
    "    layers.LSTM(256, return_sequences=True, input_shape=(seq_length, len(chars))),  # LSTM с возвратом последовательностей\n",
    "    layers.Dropout(0.2),\n",
    "    layers.LSTM(256),  # Второй LSTM слой\n",
    "    layers.Dense(128, activation='relu'),  # Полносвязный слой\n",
    "    layers.Dense(len(chars), activation='softmax')  # Выходной слой для предсказания символа\n",
    "])\n",
    "\n",
    "# Компиляция модели\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Обучение разработанной модели на обучающем наборе данных с использованием алгоритма обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1955s\u001b[0m 61ms/step - loss: 1.4683\n",
      "Epoch 2/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1952s\u001b[0m 60ms/step - loss: 1.0891\n",
      "Epoch 3/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2022s\u001b[0m 63ms/step - loss: 1.0505\n",
      "Epoch 4/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1982s\u001b[0m 61ms/step - loss: 1.0296\n",
      "Epoch 5/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2196s\u001b[0m 68ms/step - loss: 1.0169\n",
      "Epoch 6/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2129s\u001b[0m 66ms/step - loss: 1.0058\n",
      "Epoch 7/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2004s\u001b[0m 62ms/step - loss: 0.9986\n",
      "Epoch 8/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1979s\u001b[0m 61ms/step - loss: 0.9918\n",
      "Epoch 9/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2035s\u001b[0m 63ms/step - loss: 0.9867\n",
      "Epoch 10/10\n",
      "\u001b[1m32271/32271\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2083s\u001b[0m 65ms/step - loss: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x38becdaf0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучение модели\n",
    "model.fit(X, y, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Применение обученной модели для прогнозирования значений временного ряда на тестовом наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "and god said, aawin that t osan thel dit hteahil,m, , netht, ni ,eue ixh ni   uetice, e , tetelh,aa t ree eh,aim\n"
     ]
    }
   ],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds + 1e-10) / temperature  # Add a small value to avoid log(0)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)  # Normalize to get probabilities\n",
    "    return np.random.choice(len(preds), p=preds)  # Sample from the probability distribution\n",
    "\n",
    "def generate_text(model, start_string, num_generate=100, temperature=1.0):\n",
    "    # Prepare the input for the model\n",
    "    input_eval = np.zeros((1, seq_length, len(chars)))  # Create an empty array\n",
    "    for i, char in enumerate(start_string):\n",
    "        input_eval[0, i, char_to_index[char]] = 1\n",
    "\n",
    "    generated_text = start_string\n",
    "\n",
    "    for _ in range(num_generate):\n",
    "        predictions = model.predict(input_eval)\n",
    "        predicted_id = sample(predictions[-1], temperature)  # Sample using the new function\n",
    "\n",
    "        generated_text += index_to_char[predicted_id]\n",
    "\n",
    "        # Update input for the next iteration\n",
    "        input_eval = np.roll(input_eval, -1, axis=1)  # Shift left\n",
    "        input_eval[0, -1, predicted_id] = 1  # Add new character\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# Generating text with a specified temperature\n",
    "generated_text = generate_text(model, \"And God said\".lower(), num_generate=100, temperature=0.2)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Анализ полученных результатов, выявление достоинств и недостатков модели.\n",
    "\n",
    "Оценка результатов генерации текста RNN\n",
    "\n",
    "1.\tПерплексия: Перплексия (Perplexity) измеряет, насколько модель “смущена” при генерации текста. Чем ниже перплексия, тем лучше модель предсказывает последовательности символов, основываясь на обучающем наборе. Расчёт перплексии позволит количественно оценить качество предсказаний модели. В данном случае, скорее всего, перплексия будет высокой, так как модель генерирует текст без явного смысла и логической структуры.\n",
    "2.\tСходство с исходным текстом: Сгенерированный текст имеет несколько признаков оригинального текста, такие как повторение некоторых символов и небольшие совпадения в структуре слов. Однако, отсутствует семантическая связь и логические фразы. Это указывает на то, что модель плохо запомнила шаблоны слов и фраз в исходных данных.\n",
    "3.\tСубъективное качество текста: На основе примера видно, что текст не несёт осмысленных фраз. Модель выучила только некоторые комбинации символов и слова частично, но ещё не понимает структуры предложений или правил языка, что делает текст бессмысленным.\n",
    "\n",
    "Рекомендации для улучшения\n",
    "\n",
    "- Увеличить объём данных: Для более осмысленных результатов модели требуется больше данных, поскольку текст из 10,000 строк недостаточен для улавливания паттернов длинных текстов, таких как Библия.\n",
    "- Повысить количество эпох обучения: Дополнительные эпохи могут улучшить обучение модели и привести к более осмысленному тексту.\n",
    "- Использовать более сложную архитектуру: Добавление слоёв или увеличение нейронов в RNN может помочь лучше захватывать контексты и зависимости между символами и словами.\n",
    "\n",
    "Эти шаги помогут добиться большей осмысленности и когерентности сгенерированного текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Контрольные вопросы\n",
    "\n",
    "#### 1. Чем отличается рекуррентная нейронная сеть от обычной прямой нейронной сети?\n",
    "\n",
    "Рекуррентные нейронные сети (РНС) и обычные прямые нейронные сети (или полносвязные нейронные сети) отличаются в основном своей архитектурой и предназначением. Вот ключевые отличия:\n",
    "\n",
    "1. Архитектура\n",
    "\n",
    "\t- Прямые нейронные сети: Состоят из входного слоя, одного или нескольких скрытых слоев и выходного слоя. Данные передаются в одном направлении: от входного к выходному. Каждый нейрон в слое связан с каждым нейроном следующего слоя.\n",
    "\t- Рекуррентные нейронные сети: Имеют циклические соединения, что позволяет передавать информацию не только вперед, но и назад. Это означает, что состояние сети может зависеть от предыдущих состояний, что позволяет обрабатывать последовательные данные (например, временные ряды, текст).\n",
    "\n",
    "2. Обработка данных\n",
    "\n",
    "\t- Прямые нейронные сети: Лучше подходят для обработки фиксированных входных данных, таких как изображения, где каждый элемент не зависит от предыдущих.\n",
    "\t- Рекуррентные нейронные сети: Предназначены для обработки последовательностей, где порядок и контекст данных имеют значение, например, в текстах, временных рядах или аудиосигналах.\n",
    "\n",
    "3. Запоминание информации\n",
    "\n",
    "\t- Прямые нейронные сети: Запоминают информацию только через параметры (веса) сети, которые обучаются во время тренировки.\n",
    "\t- Рекуррентные нейронные сети: Могут сохранять информацию о предыдущих входах благодаря внутреннему состоянию (или скрытому состоянию), что позволяет им “помнить” предыдущие данные и учитывать их в текущих вычислениях.\n",
    "\n",
    "4. Обучение\n",
    "\n",
    "\t- Прямые нейронные сети: Используют стандартные алгоритмы обратного распространения (backpropagation) для обучения.\n",
    "\t- Рекуррентные нейронные сети: Используют модифицированный алгоритм обратного распространения, известный как обратное распространение через время (Backpropagation Through Time, BPTT), для учета зависимостей во времени.\n",
    "\n",
    "#### 2. Какие проблемы могут возникнуть при обучении рекуррентных нейронных сетей и как они могут быть решены?\n",
    "\n",
    "Обучение рекуррентных нейронных сетей (РНС) может столкнуться с несколькими проблемами, связанными с особенностями обработки последовательных данных. Вот основные из них и возможные решения:\n",
    "\n",
    "1. Проблема исчезающего градиента\n",
    "\n",
    "\t- Описание: При обучении РНС, особенно на длинных последовательностях, градиенты, которые используются для обновления весов, могут стремиться к нулю. Это приводит к тому, что обновления весов становятся слишком малыми, и сеть не может учиться эффективно.\n",
    "\t- Решение:\n",
    "        - Использование LSTM (Long Short-Term Memory) и GRU (Gated Recurrent Units): Эти архитектуры содержат специальные механизмы (гейты), которые позволяют лучше сохранять долгосрочные зависимости и предотвращают исчезновение градиента.\n",
    "        - Инициализация весов: Применение более подходящей инициализации весов может помочь смягчить проблему.\n",
    "        - Регуляризация: Использование методов регуляризации, таких как L2-регуляризация, может помочь уменьшить влияние исчезающих градиентов.\n",
    "\n",
    "2. Проблема взрывного градиента\n",
    "\n",
    "\t- Описание: Противоположная проблема, при которой градиенты становятся слишком большими, что может привести к нестабильности во время обучения и переполнению.\n",
    "\t- Решение:\n",
    "        - Ограничение градиента (Gradient Clipping): Установка порога для градиентов, чтобы избежать их слишком большого значения, что помогает контролировать обновления весов.\n",
    "        - Регуляризация: Аналогично, регуляризация может помочь предотвратить переполнение.\n",
    "\n",
    "3. Долгосрочные зависимости\n",
    "\n",
    "\t- Описание: РНС могут плохо справляться с задачами, где важны зависимости на больших расстояниях в последовательности. Это может привести к потере информации.\n",
    "\t- Решение:\n",
    "        - Использование LSTM и GRU: Эти архитектуры специально разработаны для обработки долгосрочных зависимостей.\n",
    "        - Увеличение объема данных: Создание или сбор дополнительных данных, которые подчеркивают долгосрочные зависимости, может помочь сети лучше их изучить.\n",
    "\n",
    "4. Сложность обучения\n",
    "\n",
    "\t- Описание: РНС могут быть сложными для обучения, особенно если они имеют глубокую архитектуру или длинные последовательности.\n",
    "\t- Решение:\n",
    "        - Упрощение архитектуры: Использование менее сложных моделей или уменьшение количества слоев может помочь.\n",
    "        - Использование предварительно обученных моделей: Применение трансферного обучения с использованием заранее обученных моделей может ускорить процесс обучения.\n",
    "\n",
    "5. Затраты на вычисления\n",
    "\n",
    "\t- Описание: Обучение РНС может быть вычислительно затратным, особенно для длинных последовательностей.\n",
    "\t- Решение:\n",
    "        - Использование GPU: Обучение на графических процессорах может значительно ускорить процесс.\n",
    "        - Пакетная обработка: Обработка данных партиями (batch processing) для более эффективного использования ресурсов.\n",
    "\n",
    "#### 3. Какая роль у рекуррентного слоя в рекуррентной нейронной сети?\n",
    "\n",
    "Рекуррентный слой в рекуррентной нейронной сети (РНС) играет ключевую роль в обработке последовательных данных. Вот основные функции и характеристики рекуррентного слоя:\n",
    "\n",
    "1. Обработка последовательной информации\n",
    "\n",
    "\t- Рекуррентный слой способен принимать последовательности данных (например, текст, временные ряды, аудио) и обрабатывать их поэлементно, сохраняя информацию о предыдущих состояниях. Это позволяет сети учитывать контекст и взаимосвязи между элементами последовательности.\n",
    "\n",
    "2. Сохранение состояния\n",
    "\n",
    "\t- Рекуррентные слои используют скрытое состояние (hidden state), которое обновляется на каждом временном шаге. Это состояние хранит информацию о предыдущих входах, позволяя модели “помнить” о контексте, что критично для задач, где порядок данных имеет значение.\n",
    "\n",
    "3. Циклические соединения\n",
    "\n",
    "\t- В отличие от обычных слоев, рекуррентные слои имеют циклические соединения, которые позволяют передавать информацию не только вперед, но и назад. Это создает возможность для передачи контекста из предыдущих временных шагов на текущий шаг.\n",
    "\n",
    "4. Гибкость в длине входа\n",
    "\n",
    "\t- Рекуррентные слои могут обрабатывать последовательности переменной длины, что делает их подходящими для различных типов данных, таких как предложения с разным количеством слов или временные ряды с разным количеством наблюдений.\n",
    "\n",
    "5. Изучение временных зависимостей\n",
    "\n",
    "\t- Рекуррентные слои способны выявлять и изучать временные зависимости, что позволяет эффективно решать задачи, такие как прогнозирование временных рядов, анализ текстов и распознавание речи.\n",
    "\n",
    "Применение\n",
    "\n",
    "Рекуррентные слои могут использоваться в различных архитектурах, таких как:\n",
    "\n",
    "- LSTM (Long Short-Term Memory): Расширенный рекуррентный слой, который помогает преодолевать проблемы исчезающего градиента и сохранять долгосрочные зависимости.\n",
    "- GRU (Gated Recurrent Units): Более простая альтернатива LSTM, которая также решает проблемы с долгосрочными зависимостями, но с меньшим числом параметров.\n",
    "\n",
    "#### 4. Какие метрики можно использовать для оценки результатов прогнозирования временных рядов?\n",
    "\n",
    "Для оценки результатов прогнозирования временных рядов можно использовать различные метрики. Вот некоторые из наиболее распространенных:\n",
    "\n",
    "1. Средняя абсолютная ошибка (MAE)\n",
    "\n",
    "\t- Формула: ￼$  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2  $\n",
    "\t- Описание: Измеряет среднюю абсолютную разницу между фактическими значениями и прогнозами. MAE легче интерпретировать, так как выражается в тех же единицах, что и данные.\n",
    "\n",
    "2. Средняя квадратичная ошибка (MSE)\n",
    "\n",
    "\t- Формула: ￼$  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2  $\n",
    "\t- Описание: Измеряет среднюю квадратичную разницу между фактическими значениями и прогнозами. Меньшие значения MSE указывают на лучшее качество модели, но более чувствительна к выбросам.\n",
    "\n",
    "3. Корень средней квадратичной ошибки (RMSE)\n",
    "\n",
    "\t- Формула: $  \\text{RMSE} = \\sqrt{\\text{MSE}}  $\n",
    "\t- Описание: Это квадратный корень из MSE. RMSE выражается в тех же единицах, что и данные, и позволяет легче интерпретировать ошибки.\n",
    "\n",
    "4. Средняя абсолютная процентная ошибка (MAPE)\n",
    "\n",
    "\t- Формула: ￼ $ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}i)^2}{\\sum{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "\t- Описание: Измеряет среднюю абсолютную ошибку в процентах. Полезна для оценки производительности модели, особенно когда значения данных варьируются.\n",
    "\n",
    "5. R-квадрат (R²)\n",
    "\n",
    "\t- Формула: ￼￼$ R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}i)^2}{\\sum{i=1}^{n} (y_i - \\bar{y})^2} $\n",
    "\t- Описание: Указывает на долю вариации в зависимой переменной, объясненную моделью. Значения R² находятся в диапазоне от 0 до 1, где 1 означает идеальное соответствие.\n",
    "\n",
    "6. Долговременные метрики\n",
    "\n",
    "\t- Показатели устойчивости модели: Такие как Mean Absolute Scaled Error (MASE), которые учитывают производительность модели по сравнению с простой моделью, предсказывающей среднее значение временного ряда.\n",
    "\n",
    "7. Графическое представление\n",
    "\n",
    "\t- Визуализация остаточных ошибок на графиках может помочь в выявлении паттернов, которые могут быть неявными в числовых метриках."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
